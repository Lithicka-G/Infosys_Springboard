{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MILESTONE 2: ADVANCED TEXT SUMMARIZATION WITH INTERACTIVE UI'S AND VISUALIZATION**\n",
    "TextMorph: covers advanced text summarization, evaluation with metrics, two interactive UIs in Colab, testing on 10+ sample texts, and visualizing model results with plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 1:** Install Libraries\n",
    "This cell installs all necessary libraries for the application to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# =============================\n",
    "# INSTALL DEPENDENCIES\n",
    "# =============================\n",
    "\n",
    "# Install all required libraries quietly\n",
    "!pip install ipywidgets transformers torch sentencepiece huggingface_hub pypdf evaluate scikit-learn sentence-transformers matplotlib seaborn pandas nltk textstat rouge_score accelerate --quiet; # accelerate is needed for efficient multi-device model loading\n",
    "print(\"✅ All dependencies installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 2:** Import Libraries And Authenticate\n",
    "This cell imports all required Python modules and securely logs into the Hugging Face Hub using your Colab secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# =============================\n",
    "# SETUP AND AUTHENTICATION\n",
    "# =============================\n",
    "\n",
    "# Import Libraries & Authenticate\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pypdf\n",
    "import evaluate\n",
    "import nltk\n",
    "import io\n",
    "import warnings\n",
    "import time\n",
    "import textstat\n",
    "from math import pi\n",
    "\n",
    "# --- SETUP AND AUTHENTICATION ---\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore warnings globally\n",
    "\n",
    "# CORRECTED: Download the 'punkt' resource and the specific 'punkt_tab' to fix the TextRank error\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('punkt_tab', quiet=True)  # <-- This line explicitly fixes the error\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading NLTK data: {e}\")\n",
    "\n",
    "# Securely get the token from Colab secrets and login to Hugging Face Hub\n",
    "try:\n",
    "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"✅ Hugging Face Hub login successful.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        \"🛑 Hugging Face Hub login failed. \"\n",
    "        \"Please ensure you have set the 'HF_TOKEN' secret correctly.\\n\"\n",
    "        f\"Error: {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 3:** Load AI Models (Pre-computation)\n",
    "We load models like TinyLlama, Phi-2, BART-large-cnn, Gemma for Abstractive Summarization and TextRank for Extractive Summarization. It loads into the memory before any UI is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# =============================\n",
    "# LOAD MODELS (PRE-COMPUTATION)\n",
    "# =============================\n",
    "\n",
    "# Load Models\n",
    "print(\"Loading AI models... This may take a few minutes. ⏳\")\n",
    "\n",
    "# Use GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dictionary to hold all loaded models\n",
    "MODELS = {}\n",
    "\n",
    "try:\n",
    "    # --- Abstractive Summarization Models ---\n",
    "\n",
    "    # Model 1: TinyLlama-1.1B-Chat\n",
    "    model_id_tiny = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "    MODELS['tinyllama'] = {\n",
    "        'tokenizer': AutoTokenizer.from_pretrained(model_id_tiny),\n",
    "        'model': AutoModelForCausalLM.from_pretrained(\n",
    "            model_id_tiny,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\"\n",
    "        ),\n",
    "        'name': \"TinyLlama-1.1B-Chat\"\n",
    "    }\n",
    "    print(\"✅ Loaded TinyLlama-1.1B-Chat.\")\n",
    "\n",
    "    # Model 2: Phi-2 (microsoft/phi-2)\n",
    "    model_id_phi = \"microsoft/phi-2\"\n",
    "    MODELS['phi'] = {\n",
    "        'tokenizer': AutoTokenizer.from_pretrained(model_id_phi, trust_remote_code=True),\n",
    "        'model': AutoModelForCausalLM.from_pretrained(\n",
    "            model_id_phi,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        ),\n",
    "        'name': \"Phi-2\"\n",
    "    }\n",
    "    print(\"✅ Loaded Phi-2.\")\n",
    "\n",
    "    # Model 3: BART-Large-CNN\n",
    "    model_id_bart = \"facebook/bart-large-cnn\"\n",
    "    MODELS['bart'] = {\n",
    "        'summarizer': pipeline(\n",
    "            \"summarization\",\n",
    "            model=model_id_bart,\n",
    "            device=0 if device==\"cuda\" else -1\n",
    "        ),\n",
    "        'name': \"BART-Large-CNN\"\n",
    "    }\n",
    "    print(\"✅ Loaded BART-Large-CNN.\")\n",
    "\n",
    "    # Model 4: Gemma-2B-IT\n",
    "    model_id_gemma = \"google/gemma-2b-it\"\n",
    "    MODELS['gemma'] = {\n",
    "        'tokenizer': AutoTokenizer.from_pretrained(model_id_gemma, trust_remote_code=True),\n",
    "        'model': AutoModelForCausalLM.from_pretrained(\n",
    "            model_id_gemma,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        ),\n",
    "        'name': \"Gemma-2B-IT\"\n",
    "    }\n",
    "    print(\"✅ Loaded Gemma-2B-IT.\")\n",
    "\n",
    "    # --- Extractive Summarization Model (TextRank with embeddings) ---\n",
    "    MODELS['embedding'] = {\n",
    "        'model': SentenceTransformer('all-MiniLM-L6-v2', device=device),\n",
    "        'name': \"TextRank (Embeddings)\"\n",
    "    }\n",
    "    print(\"✅ Loaded Sentence Transformer for TextRank.\")\n",
    "\n",
    "    print(\"\\n🎉 All models loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"🛑 Error loading models: {e}. Please check your token and model access permissions.\")\n",
    "    exit()\n",
    "\n",
    "# --- Load ROUGE metric for evaluation ---\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "print(\"✅ ROUGE metric loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 4:** Define Shared Backend Logic\n",
    "This cell defines common functions for text processing, running models, computing metrics, and creating plots used by both UIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# =============================\n",
    "# SHARED BACKEND LOGIC\n",
    "# =============================\n",
    "\n",
    "# --- Model Inference ---\n",
    "\n",
    "def generate_with_chat_template_model(model_key, prompt, max_new_tokens=250):\n",
    "    \"\"\"Handles models like TinyLlama and Gemma that use a chat template.\"\"\"\n",
    "    tokenizer = MODELS[model_key]['tokenizer']\n",
    "    model = MODELS[model_key]['model']\n",
    "    chat = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    formatted_prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer.encode(formatted_prompt, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(input_ids=inputs, max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
    "\n",
    "def generate_with_instruct_model(model_key, prompt, max_new_tokens=250):\n",
    "    \"\"\"Handles models like Phi that use a simple instruction format.\"\"\"\n",
    "    tokenizer = MODELS[model_key]['tokenizer']\n",
    "    model = MODELS[model_key]['model']\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False).to(model.device)\n",
    "    outputs = model.generate(**inputs, max_length=len(inputs[\"input_ids\"][0]) + max_new_tokens)\n",
    "    decoded_output = tokenizer.batch_decode(outputs)[0]\n",
    "    if \"Output:\" in decoded_output:\n",
    "        return decoded_output.split(\"Output:\")[1].strip()\n",
    "    return decoded_output  # Fallback if format is unexpected\n",
    "\n",
    "# --- Abstractive Summarization ---\n",
    "def summarize_abstractive(text, model_key, target_words=150):\n",
    "    \"\"\"\n",
    "    Generates abstractive summary ensuring approx same length across models.\n",
    "    target_words: approximate number of words desired in summary\n",
    "    \"\"\"\n",
    "    max_tokens = target_words * 2  # rough estimate (model tokens ≈ 2× words)\n",
    "    truncated_text = text[:2000]  # keep input manageable\n",
    "\n",
    "    if model_key in ['tinyllama', 'gemma']:\n",
    "        prompt = f\"Provide a concise, abstractive summary of the following text in about {target_words} words:\\n\\n{truncated_text}\"\n",
    "        summary = generate_with_chat_template_model(model_key, prompt, max_new_tokens=max_tokens)\n",
    "    elif model_key == 'phi':\n",
    "        prompt = f\"Instruct: Summarize the following text in about {target_words} words.\\n{truncated_text}\\nOutput:\"\n",
    "        summary = generate_with_instruct_model(model_key, prompt, max_new_tokens=max_tokens)\n",
    "    elif model_key == 'bart':\n",
    "        # BART uses max_length in tokens; roughly align with target_words\n",
    "        summary = MODELS['bart']['summarizer'](\n",
    "            truncated_text,\n",
    "            max_length=target_words*2,\n",
    "            min_length=int(target_words*0.8),\n",
    "            do_sample=False\n",
    "        )[0]['summary_text']\n",
    "    else:\n",
    "        summary = \"Unsupported model.\"\n",
    "\n",
    "    # Ensure output length matches target (truncate)\n",
    "    words = summary.split()\n",
    "    if len(words) > target_words:\n",
    "        summary = \" \".join(words[:target_words])\n",
    "    return summary\n",
    "\n",
    "# --- Extractive Summarization ---\n",
    "def summarize_extractive(text, model_key, target_words=150):\n",
    "    \"\"\"\n",
    "    Extractive summarization producing approx same length across models.\n",
    "    target_words: approximate number of words desired in summary\n",
    "    \"\"\"\n",
    "    words_per_sentence = 20  # approximate words per sentence\n",
    "    num_sentences = max(1, target_words // words_per_sentence)\n",
    "\n",
    "    if model_key in ['tinyllama', 'gemma']:\n",
    "        prompt = f\"Extract the {num_sentences} most crucial sentences from the following text:\\n\\n{text[:2000]}\"\n",
    "        summary = generate_with_chat_template_model(model_key, prompt, max_new_tokens=250)\n",
    "    elif model_key == 'phi':\n",
    "        prompt = f\"Instruct: Extract the {num_sentences} most important sentences from the following text.\\n{text[:2000]}\\nOutput:\"\n",
    "        summary = generate_with_instruct_model(model_key, prompt, max_new_tokens=250)\n",
    "    elif model_key == 'embedding':\n",
    "        try:\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            if len(sentences) <= num_sentences:\n",
    "                return \" \".join(sentences)\n",
    "            embeddings = MODELS['embedding']['model'].encode(sentences, convert_to_tensor=True)\n",
    "            sim_matrix = cosine_similarity(embeddings.cpu().numpy())\n",
    "            graph = nx.from_numpy_array(sim_matrix)\n",
    "            scores = nx.pagerank(graph)\n",
    "            ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "            summary = \" \".join([s for _, s in ranked_sentences[:num_sentences]])\n",
    "        except Exception as e:\n",
    "            summary = f\"TextRank failed: {e}\"\n",
    "    else:\n",
    "        summary = \"Unsupported model.\"\n",
    "\n",
    "    # Truncate/pad to approx target_words\n",
    "    words = summary.split()\n",
    "    if len(words) > target_words:\n",
    "        summary = \" \".join(words[:target_words])\n",
    "    return summary\n",
    "\n",
    "# --- Enhanced Metrics and Visualization ---\n",
    "def calculate_metrics(summary, original_text, processing_time):\n",
    "    \"\"\"Calculates evaluation metrics: ROUGE, semantic similarity, readability, length, compression, processing time.\"\"\"\n",
    "    embedding_model = MODELS['embedding']['model']\n",
    "    embeddings = embedding_model.encode([original_text, summary])\n",
    "    semantic_sim = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "\n",
    "    rouge_res = rouge_metric.compute(predictions=[summary], references=[original_text])\n",
    "\n",
    "    return {\n",
    "        \"ROUGE-1\": round(rouge_res.get('rouge1', 0.0), 3),\n",
    "        \"ROUGE-2\": round(rouge_res.get('rouge2', 0.0), 3),\n",
    "        \"Semantic Similarity\": round(semantic_sim, 3),\n",
    "        \"Readability\": round(textstat.flesch_reading_ease(summary), 2),\n",
    "        \"Length (words)\": len(summary.split()),\n",
    "        \"Time (sec)\": round(processing_time, 2),\n",
    "        \"Compression\": f\"{(1 - (len(summary.split()) / len(original_text.split()))) * 100:.1f}%\"\n",
    "                        if len(original_text.split()) > 0 else \"N/A\"\n",
    "    }\n",
    "\n",
    "def create_bar_charts(metrics_df):\n",
    "    \"\"\"Creates bar charts for ROUGE-1, Semantic Similarity, and Processing Time.\"\"\"\n",
    "    if metrics_df.empty:\n",
    "        return None\n",
    "\n",
    "    df_sorted = metrics_df.sort_values(by=['Model']).reset_index(drop=True)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle('Model Performance Comparison', fontsize=16)\n",
    "\n",
    "    sns.barplot(data=df_sorted, x='Model', y='ROUGE-1', ax=axes[0], palette='viridis').tick_params(axis='x', rotation=45)\n",
    "    axes[0].set_title('ROUGE-1 Score')\n",
    "\n",
    "    sns.barplot(data=df_sorted, x='Model', y='Semantic Similarity', ax=axes[1], palette='viridis').tick_params(axis='x', rotation=45)\n",
    "    axes[1].set_title('Semantic Similarity')\n",
    "\n",
    "    sns.barplot(data=df_sorted, x='Model', y='Time (sec)', ax=axes[2], palette='viridis').tick_params(axis='x', rotation=45)\n",
    "    axes[2].set_title('Processing Time (seconds)')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    return fig\n",
    "\n",
    "def create_radar_chart(metrics_df):\n",
    "    \"\"\"Creates a radar chart for multi-metric comparison: ROUGE-1, Semantic Similarity, Readability.\"\"\"\n",
    "    if metrics_df.empty:\n",
    "        return None\n",
    "\n",
    "    metrics_to_plot = ['ROUGE-1', 'Semantic Similarity', 'Readability']\n",
    "    df_radar = metrics_df.copy()\n",
    "    df_radar['Readability'] = np.clip(df_radar['Readability'] / 100.0, 0, 1)\n",
    "\n",
    "    df_avg = df_radar.groupby('Model')[metrics_to_plot].mean().reset_index()\n",
    "    labels, num_vars = df_avg.columns[1:], len(df_avg.columns[1:])\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist() + [0]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "    for i, row in df_avg.iterrows():\n",
    "        values = row.drop('Model').tolist() + [row.drop('Model').tolist()[0]]\n",
    "        ax.plot(angles, values, label=row['Model'], linewidth=2)\n",
    "        ax.fill(angles, values, alpha=0.25)\n",
    "\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(labels)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "    ax.set_title(\"Multi-Metric Model Comparison\", size=15, y=1.1)\n",
    "    return fig\n",
    "\n",
    "print(\"✅ Shared backend functions are defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 5:** Input Sample Texts\n",
    "This cell has 10 sample texts from different domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sample Inputs ---\n",
    "sample_texts = [\n",
    "    \"\"\"Sample text 1: Nature is the living, breathing tapestry of our planet, encompassing everything from towering mountains to tiny insects, vast oceans to silent forests. It operates through a complex system of interdependent relationships, where every plant, animal, and microbe plays a role in maintaining balance. This intricate web of life not only sustains ecosystems but also provides essential resources like clean air, fresh water, and fertile soil that humans rely on for survival.Spending time in nature has been proven to have significant mental and physical health benefits. The sounds of rustling leaves, the sight of open landscapes, and the scent of fresh earth can reduce stress, improve mood, and enhance concentration. Whether it’s a hike through a forest trail, a swim in the ocean, or simply sitting under a tree, nature has a calming effect that reconnects people to a sense of peace and wonder often lost in modern, urban life.However, the natural world is increasingly under threat from human activities such as deforestation, pollution, and climate change. These actions disrupt delicate ecosystems and endanger countless species, including our own. Protecting and preserving nature is not just an environmental issue but a necessity for future generations. By embracing sustainable practices and fostering respect for the environment, humanity can help restore the balance and ensure that the beauty and benefits of nature endure.\"\"\",\n",
    "    \"\"\"Sample text 2: Climate change refers to long-term shifts in temperatures and weather patterns, primarily driven by human activities such as burning fossil fuels, deforestation, and industrial processes. These actions release greenhouse gases like carbon dioxide and methane into the atmosphere, trapping heat and disrupting Earth's natural climate systems. As a result, global temperatures have been rising at an unprecedented rate, leading to more extreme and unpredictable weather conditions.The impacts of climate change are already being felt across the globe. Rising sea levels threaten coastal communities, while severe droughts and floods affect food and water supplies. Heatwaves, wildfires, and stronger hurricanes are becoming more frequent and intense. These changes not only harm the environment but also pose serious risks to human health, livelihoods, and infrastructure, particularly in vulnerable regions with fewer resources to adapt.Addressing climate change requires urgent global cooperation and action. This includes reducing greenhouse gas emissions, transitioning to renewable energy sources, protecting forests, and investing in sustainable technologies. On an individual level, people can contribute by conserving energy, reducing waste, and supporting climate-conscious policies. The window for meaningful action is narrowing, but with commitment and innovation, it is still possible to limit the worst effects of climate change and protect the planet for future generations.\"\"\",\n",
    "    \"\"\"Sample text 3: Artificial Intelligence (AI) is the field of computer science focused on creating systems that can perform tasks typically requiring human intelligence. These tasks include understanding natural language, recognizing images, making decisions, and learning from data. AI systems use algorithms and large datasets to identify patterns, solve problems, and improve their performance over time—often with minimal human intervention.AI is already transforming many industries. In healthcare, it helps diagnose diseases and recommend treatments; in finance, it detects fraud and manages investments; in transportation, it's powering self-driving vehicles. Everyday applications like voice assistants, recommendation engines (like those on YouTube or Netflix), and language translation tools are also built on AI technologies. Its ability to analyze massive amounts of data quickly makes it a valuable tool across countless fields.However, AI also raises important ethical and social questions. Concerns include job displacement due to automation, biases in decision-making systems, privacy risks, and the need for transparency in how AI models work. Ensuring that AI is developed and used responsibly is crucial. This involves setting clear regulations, promoting fairness and accountability, and designing systems that align with human values and societal needs.\"\"\",\n",
    "    \"\"\"Sample text 4: The stock market is a platform where investors buy and sell shares of publicly traded companies. It serves as a key part of the global financial system, allowing businesses to raise capital by offering ownership stakes (stocks) to the public. Investors, in turn, hope to earn profits through stock price increases or dividends. Major stock markets include the New York Stock Exchange (NYSE), Nasdaq, and other global exchanges like the London Stock Exchange or Bombay Stock Exchange.Stock prices are influenced by many factors, including company performance, industry trends, economic indicators, and investor sentiment. For example, if a company reports strong earnings, its stock price may rise as investors gain confidence. Conversely, news of a weak economy or political instability can cause market volatility. Because of these dynamics, investing in stocks carries both opportunities and risks, and it often requires research, strategy, and a long-term mindset.Beyond individual investing, the stock market also reflects the overall health of an economy. When markets are performing well, it can indicate economic growth and business confidence. However, sharp declines or crashes—like those during financial crises—can lead to fear, job losses, and reduced consumer spending. As a result, governments and central banks closely monitor and sometimes intervene in markets to maintain stability and encourage economic resilience.\"\"\",\n",
    "    \"\"\"Sample text 5: Pollution is the introduction of harmful substances or energy into the environment, causing negative effects on nature and human health. It can come from various sources such as factories, vehicles, agriculture, and waste disposal. The main types of pollution include air pollution, water pollution, soil pollution, and noise pollution. Each of these affects ecosystems differently and often leads to long-term damage if not controlled.Air pollution is one of the most widespread and dangerous forms, caused mainly by emissions from vehicles, industries, and burning fossil fuels. It leads to serious health problems like asthma, lung diseases, and heart conditions. Water pollution, caused by industrial waste, plastic, sewage, and chemicals, harms marine life and contaminates drinking water sources. Soil pollution from pesticides and waste affects food safety and reduces soil fertility, while noise pollution from traffic, construction, and loudspeakers affects mental well-being.Tackling pollution requires collective efforts from individuals, industries, and governments. Solutions include using cleaner energy sources, reducing plastic use, proper waste management, and stricter environmental regulations. Public awareness and education also play a key role in changing habits and promoting sustainable living. By reducing pollution, we not only protect the environment but also ensure a healthier, safer world for current and future generations.\"\"\",\n",
    "    \"\"\"Sample text 6: Life in Japan is a blend of tradition and modernity, where ancient customs coexist with cutting-edge technology. Cities like Tokyo and Osaka are known for their fast-paced lifestyles, efficient public transportation, and advanced infrastructure. Meanwhile, rural areas offer a quieter, more traditional way of life with scenic landscapes, rice fields, and a strong sense of community. Japanese culture places a high value on respect, politeness, and cleanliness, which is reflected in daily interactions and public behavior.Work and education are central parts of life in Japan. The work culture is known for being demanding, with long hours and a strong sense of dedication to the company. However, there has been growing awareness of the need for better work-life balance. Education is rigorous and competitive, with students often attending extra classes or “juku” (cram schools) to prepare for exams. Despite the pressure, there is also a strong sense of discipline, responsibility, and group harmony that shapes both school and work environments.Outside of work and school, Japan offers a rich cultural and social life. From cherry blossom festivals and traditional tea ceremonies to anime, video games, and high-tech entertainment, there's something for everyone. The food culture is also diverse and widely appreciated, with dishes like sushi, ramen, and tempura enjoyed both locally and internationally. Whether living in a busy city or a peaceful countryside town, life in Japan is marked by a deep respect for nature, community, and continuous improvement.\"\"\",\n",
    "    \"\"\"Sample text 7: The afterlife refers to the concept of existence beyond physical death—a belief found in many religions, spiritual traditions, and philosophies. What happens after we die has been one of humanity's most profound and enduring questions. Some belief systems describe a continuation of the soul in another realm, while others suggest reincarnation or a return to the universe in some spiritual form. Though ideas vary widely, most share the idea that death is not the end, but a transition.In religious contexts, the afterlife is often tied to moral behavior in life. For example, in Christianity, it’s believed that souls go to heaven or hell based on their actions and faith. In Hinduism and Buddhism, the soul is reborn in a cycle of reincarnation, influenced by karma—the consequences of one’s actions. Meanwhile, some belief systems like certain branches of atheism or secular humanism see death as the end of consciousness, where no afterlife exists, only the legacy we leave behind.While there's no scientific proof of an afterlife, the belief in it can provide comfort, hope, and guidance. It helps people cope with grief, find meaning in suffering, and live with a sense of purpose. Whether viewed as a literal destination, a spiritual journey, or a symbolic idea, the afterlife continues to influence how cultures approach life, death, and what it means to be human.\"\"\",\n",
    "    \"\"\"Sample text 8: Pollution in India is a serious and growing concern that affects the health of millions and the sustainability of its environment. The most prominent types of pollution in the country are air pollution, water pollution, and land pollution. Rapid urbanization, industrialization, and population growth have put immense pressure on natural resources and led to widespread environmental degradation. Major cities like Delhi, Mumbai, and Kolkata often struggle with high levels of pollution due to vehicle emissions, construction dust, and industrial waste.Air pollution is especially severe in northern India, where smog and particulate matter levels often exceed safe limits. Delhi, in particular, frequently ranks among the most polluted cities in the world, especially during the winter months due to crop stubble burning, firecrackers, and weather conditions that trap pollutants close to the ground. Water pollution is also a critical issue, with rivers like the Ganges and Yamuna being heavily contaminated by sewage, industrial discharge, and religious offerings. This affects not only aquatic life but also the health of communities that rely on these water sources for drinking and daily use.To combat pollution, the Indian government has taken various steps, including launching programs like the National Clean Air Programme (NCAP) and Swachh Bharat Abhiyan (Clean India Mission). There is also growing public awareness and activism pushing for stricter enforcement of environmental laws and sustainable practices. However, more effective implementation, better waste management systems, and a shift toward green technologies are needed to achieve lasting results. Controlling pollution is essential not only for protecting the environment but also for improving the quality of life and health for people across the country.\"\"\",\n",
    "    \"\"\"Sample text 9: Cybersecurity is the practice of protecting computers, networks, data, and digital systems from unauthorized access, attacks, or damage. As technology becomes more deeply integrated into daily life—through online banking, social media, e-commerce, and cloud storage—securing digital information has become critically important. Cyber threats can come in many forms, such as viruses, malware, ransomware, phishing attacks, and data breaches, often targeting both individuals and organizations.For businesses and governments, cybersecurity is essential to prevent financial losses, protect sensitive data, and maintain trust. A single cyberattack can lead to the loss of millions of dollars, leak confidential information, or even disrupt national infrastructure. As a result, many organizations invest in firewalls, encryption, intrusion detection systems, and regular security audits. Cybersecurity professionals play a key role in monitoring threats, responding to incidents, and building systems that are resistant to attacks.On a personal level, cybersecurity involves practicing safe habits like using strong passwords, enabling two-factor authentication, keeping software updated, and being cautious about suspicious emails or links. With the rise of remote work and increased internet usage, cyber hygiene is more important than ever. As threats continue to evolve, so must our defenses—making cybersecurity a constantly changing field that requires awareness, education, and ongoing innovation.\"\"\",\n",
    "    \"\"\"Sample text 10: Anime is a style of animated entertainment that originated in Japan and has grown into a global phenomenon. Unlike typical cartoons, anime covers a wide range of genres and themes, from action and adventure to romance, fantasy, horror, and science fiction. It often features distinctive art styles, vibrant characters, and complex storytelling that appeals to both children and adults. Popular series like Naruto, Dragon Ball, One Piece, and Attack on Titan have gained massive international fan bases.One unique aspect of anime is its deep connection to Japanese culture and traditions, which are frequently woven into storylines, character designs, and settings. Anime can explore philosophical questions, social issues, and emotional experiences, making it much more than simple entertainment. Additionally, anime is not limited to TV shows; it includes movies, web series, manga (comic books), and video games, creating a rich and immersive cultural ecosystem.The global popularity of anime has led to a vibrant community of fans who create fan art, cosplay, and conventions celebrating the medium. Streaming platforms and online communities have made anime more accessible worldwide, fueling interest across all ages and backgrounds. With its creativity, emotional depth, and cultural richness, anime continues to inspire and connect people everywhere.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION A:** Summarize with All Models (Prompt UI)\n",
    "This UI is simplified for quick comparisons. Just paste your text or choose from the sample texts, choose the summary type, and it will automatically run all compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SECTION A: RUN ALL MODELS UI ---\n",
    "\n",
    "# --- State and Choices ---\n",
    "metrics_history_all = []\n",
    "\n",
    "#  Abstractive summarization models now include TinyLlama, Phi, BART, and Gemma\n",
    "abstractive_model_choices = {\n",
    "    MODELS['tinyllama']['name']: 'tinyllama',\n",
    "    MODELS['phi']['name']: 'phi',\n",
    "    MODELS['bart']['name']: 'bart',\n",
    "    MODELS['gemma']['name']: 'gemma'\n",
    "}\n",
    "\n",
    "#  Extractive summarization models: TinyLlama, Phi, and TextRank (embedding)\n",
    "extractive_model_choices = {\n",
    "    MODELS['embedding']['name']: 'embedding'\n",
    "}\n",
    "\n",
    "# --- Sample Inputs Radio Buttons ---\n",
    "sample_inputs_radio = widgets.RadioButtons(\n",
    "    options=[\"None\"] + [f\"Sample {i+1}\" for i in range(len(sample_texts))],\n",
    "    description='Sample Inputs:',\n",
    "    layout={'width': '95%'},\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def on_sample_selected(change):\n",
    "    if change['new'] is not None:\n",
    "        if change['new'] == \"None\":\n",
    "            # User will manually input text; do not change textarea\n",
    "            return\n",
    "        else:\n",
    "            idx = int(change['new'].split()[1]) - 1\n",
    "            prompt_input_all.value = sample_texts[idx]\n",
    "\n",
    "sample_inputs_radio.observe(on_sample_selected, names='value')\n",
    "\n",
    "# --- UI Widget Definitions ---\n",
    "header_all = widgets.HTML(\"<h2>Section A: Summarize with All Models</h2><p>Paste text and choose a summary type. The system will automatically run all compatible models for a full comparison.</p>\")\n",
    "prompt_input_all = widgets.Textarea(placeholder='Paste your text here to summarize...', layout={'height': '200px', 'width': '99%'})\n",
    "summary_type_all = widgets.RadioButtons(options=['Abstractive', 'Extractive'], value='Abstractive', description='Summ. Type:')\n",
    "generate_button_all = widgets.Button(description='🚀 Generate All Summaries', button_style='primary', icon='cogs')\n",
    "clear_button_all = widgets.Button(description='🧹 Clear Outputs', button_style='warning', icon='trash')\n",
    "\n",
    "# --- Output Widget Definitions ---\n",
    "summary_output_all = widgets.Output(layout={'height': '400px', 'border': '1px solid #ccc', 'padding': '10px', 'overflow': 'scroll'})\n",
    "metrics_table_output_all = widgets.Output()\n",
    "bar_plot_output_all = widgets.Output()\n",
    "radar_plot_output_all = widgets.Output()\n",
    "output_accordion_all = widgets.Accordion(children=[metrics_table_output_all, bar_plot_output_all, radar_plot_output_all])\n",
    "output_accordion_all.set_title(0, '📊 Metrics Table')\n",
    "output_accordion_all.set_title(1, '📈 Bar Charts')\n",
    "output_accordion_all.set_title(2, '✨ Radar Plot')\n",
    "\n",
    "# --- Event Handlers ---\n",
    "def on_generate_button_clicked_all(b):\n",
    "    generate_button_all.disabled = True\n",
    "    generate_button_all.description = \"Processing...\"\n",
    "    original_text, s_type = prompt_input_all.value, summary_type_all.value\n",
    "    if not original_text.strip():\n",
    "        with summary_output_all: print(\"⚠ Please paste text to summarize.\")\n",
    "        generate_button_all.disabled = False\n",
    "        generate_button_all.description = \"🚀 Generate All Summaries\"\n",
    "        return\n",
    "\n",
    "    s_keys = list(abstractive_model_choices.values()) if s_type == 'Abstractive' else list(extractive_model_choices.values())\n",
    "\n",
    "    with summary_output_all: display(HTML(f\"<hr><h2>Processing Pasted Text ({s_type})</h2>\"))\n",
    "    for model_key in s_keys:\n",
    "        model_name = MODELS[model_key]['name']\n",
    "        with summary_output_all: print(f\"⏳ Summarizing with {model_name}...\")\n",
    "        start_time = time.time()\n",
    "        summary = summarize_abstractive(original_text, model_key) if s_type == \"Abstractive\" else summarize_extractive(original_text, model_key)\n",
    "        proc_time = time.time() - start_time\n",
    "        with summary_output_all: display(HTML(f\"<h3>Summary from {model_name}</h3><p>{summary}</p>\"))\n",
    "        metrics = calculate_metrics(summary, original_text, proc_time)\n",
    "        metrics.update({'Model': model_name, 'File': 'Pasted Text', 'Type': s_type})\n",
    "        metrics_history_all.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(metrics_history_all)\n",
    "    with metrics_table_output_all: metrics_table_output_all.clear_output(wait=True); display(df)\n",
    "    with bar_plot_output_all: bar_plot_output_all.clear_output(wait=True); display(create_bar_charts(df))\n",
    "    with radar_plot_output_all: radar_plot_output_all.clear_output(wait=True); display(create_radar_chart(df))\n",
    "    generate_button_all.disabled = False\n",
    "    generate_button_all.description = \"🚀 Generate All Summaries\"\n",
    "\n",
    "def on_clear_button_clicked_all(b):\n",
    "    global metrics_history_all\n",
    "    metrics_history_all = []\n",
    "    summary_output_all.clear_output()\n",
    "    metrics_table_output_all.clear_output()\n",
    "    bar_plot_output_all.clear_output()\n",
    "    radar_plot_output_all.clear_output()\n",
    "    prompt_input_all.value = \"\"\n",
    "    sample_inputs_radio.value = \"None\"\n",
    "    with summary_output_all: print(\"Outputs cleared.\")\n",
    "\n",
    "generate_button_all.on_click(on_generate_button_clicked_all)\n",
    "clear_button_all.on_click(on_clear_button_clicked_all)\n",
    "\n",
    "# --- Assemble and Display UI with Sample Inputs ---\n",
    "input_controls_all = widgets.VBox(\n",
    "    [prompt_input_all, summary_type_all, sample_inputs_radio, widgets.HBox([generate_button_all, clear_button_all])],\n",
    "    layout=widgets.Layout(width='35%', padding='10px', border='1px solid lightgrey', border_radius='5px')\n",
    ")\n",
    "output_area_all = widgets.VBox(\n",
    "    [summary_output_all, output_accordion_all],\n",
    "    layout=widgets.Layout(width='65%', padding='10px')\n",
    ")\n",
    "app_all = widgets.VBox([header_all, widgets.HBox([input_controls_all, output_area_all])])\n",
    "\n",
    "display(app_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION B:** Summarize with Specific Models (CheckBox UI)\n",
    "This UI gives you fine-grained control, allowing you to select exaclty which models you want to run using checkboxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SECTION B: SELECT SPECIFIC MODELS UI ---\n",
    "\n",
    "# --- State and Choices ---\n",
    "metrics_history_specific = []\n",
    "\n",
    "# Reuse choices with Gemma and TextRank\n",
    "abstractive_model_choices = {\n",
    "    MODELS['tinyllama']['name']: 'tinyllama',\n",
    "    MODELS['phi']['name']: 'phi',\n",
    "    MODELS['bart']['name']: 'bart',\n",
    "    MODELS['gemma']['name']: 'gemma'\n",
    "}\n",
    "extractive_model_choices = {\n",
    "    MODELS['embedding']['name']: 'embedding'\n",
    "}\n",
    "\n",
    "# --- Sample Inputs Radio Buttons ---\n",
    "sample_inputs_radio = widgets.RadioButtons(\n",
    "    options=[\"None\"] + [f\"Sample {i+1}\" for i in range(len(sample_texts))],\n",
    "    description='Sample Inputs:',\n",
    "    layout={'width': '95%'},\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def on_sample_selected_specific(change):\n",
    "    if change['new'] is not None:\n",
    "        if change['new'] == \"None\":\n",
    "            return  # User will manually input text\n",
    "        else:\n",
    "            idx = int(change['new'].split()[1]) - 1\n",
    "            prompt_input_specific.value = sample_texts[idx]\n",
    "\n",
    "sample_inputs_radio.observe(on_sample_selected_specific, names='value')\n",
    "\n",
    "# --- UI Widget Definitions ---\n",
    "header_specific = widgets.HTML(\"<h2>Section B: Summarize with Specific Models</h2><p>Paste text, choose a summary type, and check the specific models you want to run.</p>\")\n",
    "prompt_input_specific = widgets.Textarea(placeholder='Paste your text here to summarize...', layout={'height': '200px', 'width': '99%'})\n",
    "summary_type_specific = widgets.RadioButtons(options=['Abstractive', 'Extractive'], value='Abstractive', description='Summ. Type:')\n",
    "model_checkboxes_out = widgets.Output()\n",
    "checkboxes = {}\n",
    "generate_button_specific = widgets.Button(description='🚀 Generate Summaries', button_style='primary', icon='cogs')\n",
    "clear_button_specific = widgets.Button(description='🧹 Clear Outputs', button_style='warning', icon='trash')\n",
    "\n",
    "# --- Output Widget Definitions ---\n",
    "summary_output_specific = widgets.Output(layout={'height': '400px', 'border': '1px solid #ccc', 'padding': '10px', 'overflow': 'scroll'})\n",
    "metrics_table_output_specific = widgets.Output()\n",
    "bar_plot_output_specific = widgets.Output()\n",
    "radar_plot_output_specific = widgets.Output()\n",
    "output_accordion_specific = widgets.Accordion(children=[metrics_table_output_specific, bar_plot_output_specific, radar_plot_output_specific])\n",
    "output_accordion_specific.set_title(0, '📊 Metrics Table')\n",
    "output_accordion_specific.set_title(1, '📈 Bar Charts')\n",
    "output_accordion_specific.set_title(2, '✨ Radar Plot')\n",
    "\n",
    "# --- Event Handlers ---\n",
    "def update_checkboxes(s_type):\n",
    "    \"\"\"Populate checkboxes based on summary type.\"\"\"\n",
    "    global checkboxes\n",
    "    checkboxes = {}\n",
    "    choices = abstractive_model_choices if s_type == 'Abstractive' else extractive_model_choices\n",
    "    with model_checkboxes_out:\n",
    "        model_checkboxes_out.clear_output(wait=True)\n",
    "        for name, key in choices.items():\n",
    "            checkboxes[key] = widgets.Checkbox(value=True, description=name)\n",
    "        display(widgets.VBox(list(checkboxes.values())))\n",
    "\n",
    "def on_generate_button_clicked_specific(b):\n",
    "    generate_button_specific.disabled = True\n",
    "    generate_button_specific.description = \"Processing...\"\n",
    "    original_text, s_type = prompt_input_specific.value, summary_type_specific.value\n",
    "    s_keys = [key for key, cb in checkboxes.items() if cb.value]\n",
    "\n",
    "    if not original_text.strip() or not s_keys:\n",
    "        with summary_output_specific: print(\"⚠ Please paste text and check at least one model.\")\n",
    "        generate_button_specific.disabled = False\n",
    "        generate_button_specific.description = \"🚀 Generate Summaries\"\n",
    "        return\n",
    "\n",
    "    with summary_output_specific: display(HTML(f\"<hr><h2>Processing Pasted Text ({s_type})</h2>\"))\n",
    "    for model_key in s_keys:\n",
    "        model_name = MODELS[model_key]['name']\n",
    "        with summary_output_specific: print(f\"⏳ Summarizing with {model_name}...\")\n",
    "        start_time = time.time()\n",
    "        summary = summarize_abstractive(original_text, model_key) if s_type == \"Abstractive\" else summarize_extractive(original_text, model_key)\n",
    "        proc_time = time.time() - start_time\n",
    "        with summary_output_specific: display(HTML(f\"<h3>Summary from {model_name}</h3><p>{summary}</p>\"))\n",
    "        metrics = calculate_metrics(summary, original_text, proc_time)\n",
    "        metrics.update({'Model': model_name, 'File': 'Pasted Text', 'Type': s_type})\n",
    "        metrics_history_specific.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(metrics_history_specific)\n",
    "    with metrics_table_output_specific: metrics_table_output_specific.clear_output(wait=True); display(df)\n",
    "    with bar_plot_output_specific: bar_plot_output_specific.clear_output(wait=True); display(create_bar_charts(df))\n",
    "    with radar_plot_output_specific: radar_plot_output_specific.clear_output(wait=True); display(create_radar_chart(df))\n",
    "    generate_button_specific.disabled = False\n",
    "    generate_button_specific.description = \"🚀 Generate Summaries\"\n",
    "\n",
    "def on_clear_button_clicked_specific(b):\n",
    "    global metrics_history_specific\n",
    "    metrics_history_specific = []\n",
    "    summary_output_specific.clear_output()\n",
    "    metrics_table_output_specific.clear_output()\n",
    "    bar_plot_output_specific.clear_output()\n",
    "    radar_plot_output_specific.clear_output()\n",
    "    prompt_input_specific.value = \"\"\n",
    "    sample_inputs_radio.value = \"None\"\n",
    "    with summary_output_specific: print(\"Outputs cleared.\")\n",
    "\n",
    "def on_summary_type_change_specific(change):\n",
    "    update_checkboxes(change.new)\n",
    "\n",
    "# --- Bind events ---\n",
    "generate_button_specific.on_click(on_generate_button_clicked_specific)\n",
    "clear_button_specific.on_click(on_clear_button_clicked_specific)\n",
    "summary_type_specific.observe(on_summary_type_change_specific, names='value')\n",
    "\n",
    "# --- Assemble and Display UI with Sample Inputs ---\n",
    "input_controls_specific = widgets.VBox(\n",
    "    [prompt_input_specific, summary_type_specific, sample_inputs_radio, widgets.Label(\"Select Models:\"), model_checkboxes_out, widgets.HBox([generate_button_specific, clear_button_specific])],\n",
    "    layout=widgets.Layout(width='35%', padding='10px', border='1px solid lightgrey', border_radius='5px')\n",
    ")\n",
    "output_area_specific = widgets.VBox(\n",
    "    [summary_output_specific, output_accordion_specific],\n",
    "    layout=widgets.Layout(width='65%', padding='10px')\n",
    ")\n",
    "app_specific = widgets.VBox([header_specific, widgets.HBox([input_controls_specific, output_area_specific])])\n",
    "\n",
    "# Initial population of checkboxes\n",
    "update_checkboxes('Abstractive')\n",
    "\n",
    "display(app_specific)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
