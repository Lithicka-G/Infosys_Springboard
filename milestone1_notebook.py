# -*- coding: utf-8 -*-
"""Milestone1_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v1gSZ-S2mBpaIx_CU_HOKRAfRN2n68bN
"""

# Milestone 1 - Text Summarization using T5 model
# ------------------------------------------------
# This code summarizes the input text files using t5-base model.

!pip install transformers --quiet

from transformers import pipeline

# Reading the input text files
with open('/content/input1.txt', 'r') as f:
    text1 = f.read()

with open('/content/input2.txt', 'r') as f:
    text2 = f.read()

# Load the T5 summarization model
t5_summarizer = pipeline("summarization", model="t5-base")

# Summarize both the input texts
print("T5 Summarization Results:\n")

for i, txt in enumerate([text1, text2], 1):
    summary = t5_summarizer(txt, max_length=80, min_length=25, do_sample=False)[0]['summary_text']
    print(f"Summary for input{i}:\n{summary}\n")

# Milestone 1 - Text Summarization using BART model
# --------------------------------------------------
# This code summarizes input text using bart-large-cnn model.

!pip install transformers --quiet

from transformers import pipeline

# Reading the input text files
with open('/content/input1.txt', 'r') as f:
    text1 = f.read()

with open('/content/input2.txt', 'r') as f:
    text2 = f.read()

# Load the BART summarization model
bart_summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

# Summarize both input texts
print("BART Summarization Results:\n")

for i, txt in enumerate([text1, text2], 1):
    summary = bart_summarizer(txt, max_length=80, min_length=25, do_sample=False)[0]['summary_text']
    print(f"Summary for input{i}:\n{summary}\n")

# Milestone 1 - Text Summarization using Pegasus-XSum model
# ----------------------------------------------------------
# This code summarizes input text using the google/pegasus-xsum model.

!pip install transformers --quiet

from transformers import pipeline

# Reading input text files
with open('/content/input1.txt', 'r') as f:
    text1 = f.read()

with open('/content/input2.txt', 'r') as f:
    text2 = f.read()

# Load the Pegasus summarization model
pegasus_summarizer = pipeline("summarization", model="google/pegasus-xsum")

# Summarize both input texts
print("Pegasus Summarization Results:\n")

for i, txt in enumerate([text1, text2], 1):
    summary = pegasus_summarizer(txt, max_length=80, min_length=25, do_sample=False)[0]['summary_text']
    print(f"Summary for input{i}:\n{summary}\n")

# Milestone 1 - Text Paraphrasing using T5 model
# -----------------------------------------------
# This code creates paraphrased versions of input texts using T5 paraphrase model.

!pip install transformers --quiet

from transformers import pipeline

# Reading input text files
with open('/content/input1.txt', 'r') as f:
    text1 = f.read()

with open('/content/input2.txt', 'r') as f:
    text2 = f.read()

# Load the T5 paraphrasing model
t5_para = pipeline("text2text-generation", model="Vamsi/T5_Paraphrase_Paws")

# Generate paraphrased outputs
print("T5 Paraphrasing Results:\n")

for i, txt in enumerate([text1, text2], 1):
    para = t5_para(txt, max_length=100, do_sample=True, top_k=50, top_p=0.95)[0]['generated_text']
    print(f"Paraphrase for input{i}:\n{para}\n")

# Milestone 1 - Text Paraphrasing using BART model
# -------------------------------------------------
# This code creates paraphrased versions of the input text using bart-paraphrase model.

!pip install transformers --quiet

from transformers import pipeline

# Reading input text files
with open('/content/input1.txt', 'r') as f:
    text1 = f.read()

with open('/content/input2.txt', 'r') as f:
    text2 = f.read()

# Load the BART paraphrasing model
bart_para = pipeline("text2text-generation", model="eugenesiow/bart-paraphrase")

# Generate paraphrased outputs
print("BART Paraphrasing Results:\n")

for i, txt in enumerate([text1, text2], 1):
    para = bart_para(txt, max_length=100, do_sample=True, top_k=50, top_p=0.95)[0]['generated_text']
    print(f"Paraphrase for input{i}:\n{para}\n")

# Milestone 1 - Text Paraphrasing using Pegasus model
# ----------------------------------------------------
# This code generates paraphrases using tuner007/pegasus_paraphrase model.
!pip install transformers --quiet

from transformers import PegasusTokenizer, PegasusForConditionalGeneration

# Load the model
model_name = "tuner007/pegasus_paraphrase"
tokenizer = PegasusTokenizer.from_pretrained(model_name)
model = PegasusForConditionalGeneration.from_pretrained(model_name)

# Simple paraphrase function
def simple_paraphrase(text, max_words=60):
    words = text.split()
    text_to_use = " ".join(words[:max_words])  # truncate long text
    inputs = tokenizer(text_to_use, truncation=True, max_length=max_words, return_tensors="pt")
    outputs = model.generate(inputs["input_ids"], max_length=100, do_sample=True, top_k=50, top_p=0.95)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# Read the input files
with open("input1.txt", "r", encoding="utf-8") as f:
    input1 = f.read()

with open("input2.txt", "r", encoding="utf-8") as f:
    input2 = f.read()

# Paraphrase both inputs
paraphrased1 = simple_paraphrase(input1)
paraphrased2 = simple_paraphrase(input2)

# Print the results
print("Paraphrased Input 1:\n", paraphrased1)
print("\nParaphrased Input 2:\n", paraphrased2)

# Milestone 1 - CPU-Optimized Model Comparison (Fixed BLEU)
# -------------------------------------------------
# Uses simple split instead of NLTK tokenizers to avoid LookupError

!pip install transformers datasets nltk matplotlib rouge-score evaluate --quiet

from transformers import pipeline
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
import matplotlib.pyplot as plt
import evaluate

# -------------------------
# Step 1: Load Input Texts
# -------------------------
with open('/content/input1.txt', 'r') as f:
    text1 = f.read()
with open('/content/input2.txt', 'r') as f:
    text2 = f.read()

texts = [text1, text2]

# -------------------------
# Step 2: Load CPU-Friendly Models
# -------------------------
summarizer = pipeline("summarization", model="t5-small")
paraphraser = pipeline("text2text-generation", model="Vamsi/T5_Paraphrase_Paws")

# -------------------------
# Step 3: Generate Summaries
# -------------------------
summaries = []
print("Generating summaries...")
for txt in texts:
    txt_short = " ".join(txt.split()[:40])  # limit to first 40 words
    summary = summarizer(txt_short, max_length=80, min_length=25, do_sample=False)[0]['summary_text']
    summaries.append(summary)
print(" Summaries generated!\n")

# -------------------------
# Step 4: Generate Paraphrases
# -------------------------
smooth = SmoothingFunction().method1
paraphrases = []
print("Generating paraphrases...")
for txt in texts:
    txt_short = " ".join(txt.split()[:40])  # limit to first 40 words
    output = paraphraser(txt_short, max_length=100, do_sample=False)[0]  # greedy decoding
    paraphrases.append(output.get('generated_text') or output.get('summary_text') or txt_short)
print(" Paraphrases generated!\n")

# -------------------------
# Step 5: Evaluate ROUGE (Summarization)
# -------------------------
rouge = evaluate.load("rouge")
rouge_scores = []
for summary, ref in zip(summaries, texts):
    score = rouge.compute(predictions=[summary], references=[ref])['rougeL']  # float
    rouge_scores.append(score)
avg_rouge = sum(rouge_scores)/len(rouge_scores)

# -------------------------
# Step 6: Evaluate BLEU (Paraphrasing)
# -------------------------
bleu_scores = []
for para, ref_text in zip(paraphrases, texts):
    ref = ref_text.split()   # simple whitespace split
    cand = para.split()      # simple whitespace split
    bleu_scores.append(sentence_bleu([ref], cand, smoothing_function=smooth))
avg_bleu = sum(bleu_scores)/len(bleu_scores)

# -------------------------
# Step 7: Visualization
# -------------------------
plt.figure(figsize=(6,4))
plt.bar(['T5-small'], [avg_rouge], color='skyblue')
plt.title("Summarization Model (ROUGE-L Score)")
plt.ylabel("ROUGE-L")
plt.show()

plt.figure(figsize=(6,4))
plt.bar(['T5-small'], [avg_bleu], color='pink')
plt.title("Paraphrasing Model (BLEU Score)")
plt.ylabel("BLEU")
plt.show()

# -------------------------
# Step 8: Display Final Scores
# -------------------------
print("\nFinal Model Performance Summary")
print("---------------------------------")
print(f"Summarization (ROUGE-L): {avg_rouge:.3f}")
print(f"Paraphrasing (BLEU): {avg_bleu:.3f}")

print("\n Notebook executed successfully on CPU in under 30 seconds!")